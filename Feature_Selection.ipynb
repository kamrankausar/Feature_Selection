{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature_Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SelectKBest selects the top k features that have maximum relevance with the target variable. \n",
    "It takes two parameters as input arguments, \"k\" (obviously) and the score \n",
    "function to rate the relevance of every feature with the target variable.\n",
    "For example, for a regression problem, you can supply \"feature_selection.f_regression\"\n",
    "and for a classification problem, you can supply \"feature_selection.f_classif\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "You can use SelectKBest and GridSearchCV together using a Pipeline with \n",
    "an estimator as the second step. The pipeline applies the first step by \n",
    "choosing the best k features and transforms the input data to have only \n",
    "these features. After transformation, this is then fit with your estimator.\n",
    "The GridSearchCV helps you to tune the \"number of features to be selected\"\n",
    "and the hyperparameter of the estimator, by selecting the parameters that \n",
    "give the best score on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('kbest', SelectKBest(k=10, score_func=<function f_classif at 0x7f6f0ad33d08>)), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kbest__k': [1, 2, 3, 4], 'lr__C': array([  1.00000e-10,   1.00000e-05,   1.00000e+00,   1.00000e+05,\n",
       "         1.00000e+10])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    # from sklearn.grid_search import GridSearchCV\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.feature_selection import SelectKBest, f_classif\n",
    "    import numpy as np\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    kbest = SelectKBest(f_classif)\n",
    "    pipeline = Pipeline([('kbest', kbest), ('lr', LogisticRegression())])\n",
    "    grid_search = GridSearchCV(pipeline, {'kbest__k': [1,2,3,4], 'lr__C': np.logspace(-10, 10, 5)})\n",
    "    grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
